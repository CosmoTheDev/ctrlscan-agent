name: Ctrlscan Self Scan

on:
  push:
    branches: [main]
  pull_request:
    branches: [main]
  workflow_dispatch:

permissions:
  contents: read
  pull-requests: write
  issues: write

concurrency:
  group: ctrlscan-self-scan-${{ github.event.pull_request.number || github.ref }}
  cancel-in-progress: true

env:
  GO_VERSION: "1.25.7"

jobs:
  build:
    name: Build ctrlscan
    runs-on: ubuntu-latest
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Set up Go
        uses: actions/setup-go@v5
        with:
          go-version: ${{ env.GO_VERSION }}
          cache: true

      - name: Build
        run: make build

      - name: Upload binary
        uses: actions/upload-artifact@v4
        with:
          name: ctrlscan-linux-amd64
          path: ctrlscan
          retention-days: 1

  self-scan:
    name: Ctrlscan Self Scan
    runs-on: ubuntu-latest
    needs: build
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Set up Go
        uses: actions/setup-go@v5
        with:
          go-version: ${{ env.GO_VERSION }}
          cache: true

      - name: Download ctrlscan binary
        uses: actions/download-artifact@v4.1.3
        with:
          name: ctrlscan-linux-amd64

      - name: Make binary executable
        run: chmod +x ./ctrlscan

      - name: Prepare CI paths
        id: paths
        shell: bash
        run: |
          set -euo pipefail
          HOME_DIR="${RUNNER_TEMP}/ctrlscan-home"
          BIN_DIR="${HOME_DIR}/.ctrlscan/bin"
          DB_PATH="${RUNNER_TEMP}/ctrlscan-self-scan.db"
          CFG_PATH="${RUNNER_TEMP}/ctrlscan-ci-config.json"
          REPORT_DIR="${GITHUB_WORKSPACE}/reports"
          mkdir -p "${HOME_DIR}" "${BIN_DIR}" "${REPORT_DIR}"
          {
            echo "home_dir=${HOME_DIR}"
            echo "bin_dir=${BIN_DIR}"
            echo "db_path=${DB_PATH}"
            echo "cfg_path=${CFG_PATH}"
            echo "report_dir=${REPORT_DIR}"
          } >> "$GITHUB_OUTPUT"
          echo "${BIN_DIR}" >> "$GITHUB_PATH"

      - name: Install scanner tools
        shell: bash
        run: |
          set -euo pipefail
          bash ./install/tools.sh --bin-dir "${{ steps.paths.outputs.bin_dir }}"
          echo "=== Tool Versions ==="
          syft version || true
          grype version || true
          opengrep --version || true
          trivy --version || true
          trufflehog --version || true

      - name: Create ctrlscan CI config
        shell: bash
        env:
          GH_REPO_TOKEN: ${{ github.token }}
          DB_PATH: ${{ steps.paths.outputs.db_path }}
          BIN_DIR: ${{ steps.paths.outputs.bin_dir }}
          CFG_PATH: ${{ steps.paths.outputs.cfg_path }}
        run: |
          set -euo pipefail
          python3 - <<'PY'
          import json, os
          cfg = {
              "database": {"driver": "sqlite", "path": os.environ["DB_PATH"], "dsn": ""},
              "ai": {"provider": "none", "openai_api_key": "", "model": "gpt-4o", "base_url": "", "ollama_url": "http://localhost:11434"},
              "git": {
                  "github": [{"token": os.environ.get("GH_REPO_TOKEN", ""), "host": "github.com"}],
                  "gitlab": [],
                  "azure": []
              },
              "agent": {
                  "mode": "triage",
                  "workers": 2,
                  "scan_targets": ["own_repos"],
                  "watchlist": [],
                  "scanners": ["grype", "opengrep", "trufflehog", "trivy"]
              },
              "tools": {"bin_dir": os.environ["BIN_DIR"], "prefer_docker": False},
              "gateway": {"port": 6080}
          }
          with open(os.environ["CFG_PATH"], "w", encoding="utf-8") as f:
              json.dump(cfg, f, indent=2)
          PY

      - name: Determine scan target
        id: target
        shell: bash
        env:
          EVENT_NAME: ${{ github.event_name }}
          PR_HEAD_FULL_NAME: ${{ github.event.pull_request.head.repo.full_name }}
          REPOSITORY: ${{ github.repository }}
          PR_HEAD_CLONE_URL: ${{ github.event.pull_request.head.repo.clone_url }}
          PR_HEAD_REF: ${{ github.event.pull_request.head.ref }}
          PR_HEAD_SHA: ${{ github.event.pull_request.head.sha }}
          REF_NAME: ${{ github.ref_name }}
          SHA: ${{ github.sha }}
        run: |
          set -euo pipefail
          if [ "$EVENT_NAME" = "pull_request" ]; then
            if [ "$PR_HEAD_FULL_NAME" != "$REPOSITORY" ]; then
              echo "skip_scan=true" >> "$GITHUB_OUTPUT"
              echo "skip_reason=Fork PRs are skipped by self-scan because ctrlscan scan clones by repo URL and cannot safely use elevated tokens on untrusted fork code." >> "$GITHUB_OUTPUT"
              exit 0
            fi
            {
              echo "scan_repo_url=$PR_HEAD_CLONE_URL"
              echo "scan_branch=$PR_HEAD_REF"
              echo "head_sha=$PR_HEAD_SHA"
            } >> "$GITHUB_OUTPUT"
          else
            {
              echo "scan_repo_url=https://github.com/$REPOSITORY"
              echo "scan_branch=$REF_NAME"
              echo "head_sha=$SHA"
            } >> "$GITHUB_OUTPUT"
          fi
          echo "skip_scan=false" >> "$GITHUB_OUTPUT"

      - name: Run ctrlscan self scan
        id: scan
        if: steps.target.outputs.skip_scan != 'true'
        shell: bash
        run: |
          set +e
          mkdir -p "${{ steps.paths.outputs.report_dir }}"
          HOME="${{ steps.paths.outputs.home_dir }}" \
          ./ctrlscan --config "${{ steps.paths.outputs.cfg_path }}" scan \
            --repo "${{ steps.target.outputs.scan_repo_url }}" \
            --branch "${{ steps.target.outputs.scan_branch }}" \
            --scanners grype,opengrep,trufflehog,trivy \
            --parallel \
            2>&1 | tee "${{ steps.paths.outputs.report_dir }}/ctrlscan-scan.log"
          scan_exit=${PIPESTATUS[0]}
          echo "scan_exit=${scan_exit}" >> "$GITHUB_OUTPUT"
          exit 0

      - name: Parse scan results from SQLite
        id: parse
        if: always()
        shell: bash
        run: |
          set -euo pipefail
          python3 - <<'PY'
          import json, os, sqlite3, sys
          out = os.environ["GITHUB_OUTPUT"]
          report_dir = os.environ["REPORT_DIR"]
          db_path = os.environ["DB_PATH"]
          skip_scan = os.environ.get("SKIP_SCAN", "false") == "true"
          scan_exit = int(os.environ.get("SCAN_EXIT", "0") or "0")

          summary = {
            "skipped": skip_scan,
            "skip_reason": os.environ.get("SKIP_REASON", ""),
            "scan_exit": scan_exit,
            "job_id": None,
            "job_status": "skipped" if skip_scan else "unknown",
            "repo": "",
            "branch": "",
            "critical": 0,
            "high": 0,
            "medium": 0,
            "low": 0,
            "policy_critical": 0,
            "policy_high": 0,
            "ignored_high_findings": 0,
            "scanner_counts": {"grype": 0, "opengrep": 0, "trufflehog": 0, "trivy": 0},
            "total_scanner_findings": 0,
            "conclusion": "success",
          }

          if skip_scan:
            summary["conclusion"] = "success"
          elif not os.path.exists(db_path):
            summary["conclusion"] = "failure" if scan_exit != 0 else "neutral"
            summary["job_status"] = "no_db"
          else:
            con = sqlite3.connect(db_path)
            con.row_factory = sqlite3.Row
            cur = con.cursor()
            cur.execute("""
              SELECT id, owner, repo, branch, status,
                     findings_critical, findings_high, findings_medium, findings_low
              FROM scan_jobs
              ORDER BY id DESC
              LIMIT 1
            """)
            row = cur.fetchone()
            if row:
              summary["job_id"] = row["id"]
              summary["job_status"] = row["status"]
              summary["repo"] = f'{row["owner"]}/{row["repo"]}'
              summary["branch"] = row["branch"]
              summary["critical"] = int(row["findings_critical"] or 0)
              summary["high"] = int(row["findings_high"] or 0)
              summary["medium"] = int(row["findings_medium"] or 0)
              summary["low"] = int(row["findings_low"] or 0)

              cur.execute("""
                SELECT scanner_name, COALESCE(SUM(findings_count), 0) AS n
                FROM scan_job_scanners
                WHERE scan_job_id = ?
                GROUP BY scanner_name
              """, (row["id"],))
              for r in cur.fetchall():
                summary["scanner_counts"][r["scanner_name"]] = int(r["n"] or 0)
              summary["total_scanner_findings"] = sum(summary["scanner_counts"].values())

              # Policy-specific severity counts can exclude known scanner false positives
              # while preserving raw rollups in the comment and artifacts.
              summary["policy_critical"] = summary["critical"]
              summary["policy_high"] = summary["high"]

              cur.execute("""
                SELECT vulnerability_id, package_name, severity
                FROM sca_vulns
                WHERE scan_job_id = ?
              """, (row["id"],))
              for vuln in cur.fetchall():
                vuln_id = (vuln["vulnerability_id"] or "").strip()
                pkg = (vuln["package_name"] or "").strip()
                sev = (vuln["severity"] or "").strip().lower()
                # grype currently normalizes GitHub Action versions like v4.1.3 to v4
                # for some action refs and may report a false-positive high here.
                if vuln_id == "GHSA-cxww-7g56-2vh6" and pkg == "actions/download-artifact" and sev == "high":
                  summary["ignored_high_findings"] += 1
                  if summary["policy_high"] > 0:
                    summary["policy_high"] -= 1

            con.close()

            if scan_exit != 0:
              summary["conclusion"] = "failure"
            elif summary["scanner_counts"].get("trufflehog", 0) > 0:
              summary["conclusion"] = "failure"
            elif summary["policy_critical"] > 0 or summary["policy_high"] > 0:
              summary["conclusion"] = "failure"
            elif summary["medium"] > 0 or summary["scanner_counts"].get("trivy", 0) > 0:
              summary["conclusion"] = "neutral"
            else:
              summary["conclusion"] = "success"

          os.makedirs(report_dir, exist_ok=True)
          with open(os.path.join(report_dir, "self-scan-summary.json"), "w", encoding="utf-8") as f:
            json.dump(summary, f, indent=2)

          with open(out, "a", encoding="utf-8") as f:
            for key, value in [
              ("skipped", str(summary["skipped"]).lower()),
              ("skip_reason", summary["skip_reason"]),
              ("scan_exit", str(summary["scan_exit"])),
              ("job_id", "" if summary["job_id"] is None else str(summary["job_id"])),
              ("job_status", summary["job_status"]),
              ("repo", summary["repo"]),
              ("branch", summary["branch"]),
              ("critical", str(summary["critical"])),
              ("high", str(summary["high"])),
              ("medium", str(summary["medium"])),
              ("low", str(summary["low"])),
              ("policy_critical", str(summary["policy_critical"])),
              ("policy_high", str(summary["policy_high"])),
              ("ignored_high_findings", str(summary["ignored_high_findings"])),
              ("grype_count", str(summary["scanner_counts"].get("grype", 0))),
              ("opengrep_count", str(summary["scanner_counts"].get("opengrep", 0))),
              ("trufflehog_count", str(summary["scanner_counts"].get("trufflehog", 0))),
              ("trivy_count", str(summary["scanner_counts"].get("trivy", 0))),
              ("total_findings", str(summary["total_scanner_findings"])),
              ("conclusion", summary["conclusion"]),
            ]:
              f.write(f"{key}={value}\n")
          PY
        env:
          DB_PATH: ${{ steps.paths.outputs.db_path }}
          REPORT_DIR: ${{ steps.paths.outputs.report_dir }}
          SKIP_SCAN: ${{ steps.target.outputs.skip_scan }}
          SKIP_REASON: ${{ steps.target.outputs.skip_reason }}
          SCAN_EXIT: ${{ steps.scan.outputs.scan_exit }}

      - name: Export finding details from SQLite
        id: details
        if: ${{ always() && steps.parse.outputs.skipped != 'true' && steps.parse.outputs.job_id != '' }}
        shell: bash
        run: |
          set -euo pipefail
          python3 - <<'PY'
          import json, os, sqlite3

          db_path = os.environ["DB_PATH"]
          report_dir = os.environ["REPORT_DIR"]
          job_id = int(os.environ["JOB_ID"])
          out = os.environ["GITHUB_OUTPUT"]

          os.makedirs(report_dir, exist_ok=True)
          con = sqlite3.connect(db_path)
          con.row_factory = sqlite3.Row
          cur = con.cursor()

          severity_rank = {
              "CRITICAL": 5, "Critical": 5, "critical": 5,
              "HIGH": 4, "High": 4, "high": 4, "ERROR": 4, "Error": 4, "error": 4,
              "MEDIUM": 3, "Medium": 3, "medium": 3, "WARNING": 3, "Warning": 3, "warning": 3,
              "LOW": 2, "Low": 2, "low": 2,
              "INFO": 1, "Info": 1, "info": 1,
          }

          findings = []

          def add(table, kind, cols_sql, mapper):
              q = f"SELECT {cols_sql} FROM {table} WHERE scan_job_id = ?"
              try:
                  cur.execute(q, (job_id,))
                  for row in cur.fetchall():
                      findings.append(mapper(row))
              except sqlite3.OperationalError:
                  return

          add(
              "sast_findings",
              "sast",
              "id, severity, check_id, file_path, line_start, message, status",
              lambda r: {
                  "kind": "sast",
                  "severity": r["severity"] or "",
                  "rule": r["check_id"] or "",
                  "location": f'{r["file_path"]}:{r["line_start"]}' if (r["file_path"] or "") else "",
                  "title": (r["message"] or "")[:200],
                  "status": r["status"] or "",
              },
          )
          add(
              "sca_vulns",
              "sca",
              "id, severity, vulnerability_id, package_name, version_affected, version_remediation, status",
              lambda r: {
                  "kind": "sca",
                  "severity": r["severity"] or "",
                  "rule": r["vulnerability_id"] or "",
                  "location": (r["package_name"] or "") + (f'@{r["version_affected"]}' if (r["version_affected"] or "") else ""),
                  "title": ("fix " + (r["version_remediation"] or "")) if (r["version_remediation"] or "") else "",
                  "status": r["status"] or "",
              },
          )
          add(
              "secrets_findings",
              "secrets",
              "id, severity, detector_name, detector_type, file_path, line_number, status",
              lambda r: {
                  "kind": "secrets",
                  "severity": r["severity"] or "",
                  "rule": (r["detector_name"] or "") + (f'/{r["detector_type"]}' if (r["detector_type"] or "") else ""),
                  "location": f'{r["file_path"]}:{r["line_number"]}' if (r["file_path"] or "") else "",
                  "title": "Potential secret detected",
                  "status": r["status"] or "",
              },
          )
          add(
              "iac_findings",
              "iac",
              "id, severity, check_id, title, file_path, line_start, status",
              lambda r: {
                  "kind": "iac",
                  "severity": r["severity"] or "",
                  "rule": r["check_id"] or "",
                  "location": f'{r["file_path"]}:{r["line_start"]}' if (r["file_path"] or "") else "",
                  "title": (r["title"] or "")[:200],
                  "status": r["status"] or "",
              },
          )

          findings.sort(key=lambda f: (-severity_rank.get(f["severity"], 0), f["kind"], f["location"], f["rule"]))
          top = findings[:20]

          with open(os.path.join(report_dir, "findings-top.json"), "w", encoding="utf-8") as f:
              json.dump(top, f, indent=2)

          md_lines = [
              "# Top Findings (from SQLite)",
              "",
              f"Scan Job: #{job_id}",
              "",
          ]
          if not top:
              md_lines.append("No normalized findings rows found for this scan job.")
          else:
              md_lines.extend([
                  "| Kind | Severity | Rule/CVE | Location | Detail | Status |",
                  "|---|---|---|---|---|---|",
              ])
              for item in top:
                  def esc(s):
                      return str(s or "").replace("|", "\\|").replace("\n", " ").strip()
                  md_lines.append(
                      f'| {esc(item["kind"])} | {esc(item["severity"])} | {esc(item["rule"])} | {esc(item["location"])} | {esc(item["title"])} | {esc(item["status"])} |'
                  )

          preview_md = "\n".join(md_lines) + "\n"
          preview_path = os.path.join(report_dir, "findings-top.md")
          with open(preview_path, "w", encoding="utf-8") as f:
              f.write(preview_md)

          with open(out, "a", encoding="utf-8") as f:
              f.write(f"has_details={'true' if bool(top) else 'false'}\n")
              f.write(f"details_markdown_path={preview_path}\n")
          con.close()
          PY
        env:
          DB_PATH: ${{ steps.paths.outputs.db_path }}
          REPORT_DIR: ${{ steps.paths.outputs.report_dir }}
          JOB_ID: ${{ steps.parse.outputs.job_id }}

      - name: Publish job summary
        if: always()
        shell: bash
        run: |
          {
            echo "## Ctrlscan Self Scan"
            echo ""
            if [ "${{ steps.parse.outputs.skipped }}" = "true" ]; then
              echo "- Status: skipped"
              echo "- Reason: ${{ steps.parse.outputs.skip_reason }}"
              exit 0
            fi
            echo "- Repo: \`${{ steps.parse.outputs.repo || steps.target.outputs.scan_repo_url }}\`"
            echo "- Branch: \`${{ steps.parse.outputs.branch || steps.target.outputs.scan_branch }}\`"
            echo "- Scan command exit: \`${{ steps.parse.outputs.scan_exit }}\`"
            echo "- Scan job: \`#${{ steps.parse.outputs.job_id }}\` (\`${{ steps.parse.outputs.job_status }}\`)"
            echo ""
            echo "### Scanner Counts"
            echo ""
            echo "| Scanner | Findings |"
            echo "|---|---:|"
            echo "| grype | ${{ steps.parse.outputs.grype_count }} |"
            echo "| opengrep | ${{ steps.parse.outputs.opengrep_count }} |"
            echo "| trufflehog | ${{ steps.parse.outputs.trufflehog_count }} |"
            echo "| trivy | ${{ steps.parse.outputs.trivy_count }} |"
            echo "| **Total** | **${{ steps.parse.outputs.total_findings }}** |"
            echo ""
            echo "### Severity Rollup"
            echo ""
            echo "| Critical | High | Medium | Low |"
            echo "|---:|---:|---:|---:|"
            echo "| ${{ steps.parse.outputs.critical }} | ${{ steps.parse.outputs.high }} | ${{ steps.parse.outputs.medium }} | ${{ steps.parse.outputs.low }} |"
            echo ""
            if [ "${{ steps.parse.outputs.ignored_high_findings }}" != "0" ]; then
              echo "- Policy exclusions applied: ignored \`${{ steps.parse.outputs.ignored_high_findings }}\` known false-positive high finding(s) for \`actions/download-artifact\` GHSA version normalization."
              echo ""
            fi
            echo "Policy result: \`${{ steps.parse.outputs.conclusion }}\` (fail on secrets or critical/high)"
            if [ -f "reports/findings-top.md" ]; then
              echo ""
              cat "reports/findings-top.md"
            fi
          } >> "$GITHUB_STEP_SUMMARY"

      - name: Upload scan artifacts
        id: upload_artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: ctrlscan-self-scan-reports
          path: |
            reports/
          retention-days: 14

      - name: Comment on PR with self-scan summary
        if: ${{ always() && github.event_name == 'pull_request' }}
        continue-on-error: true
        uses: actions/github-script@v7
        with:
          script: |
            const marker = '<!-- ctrlscan-self-scan -->';
            const skipped = '${{ steps.parse.outputs.skipped }}' === 'true';
            const conclusion = '${{ steps.parse.outputs.conclusion }}' || 'unknown';
            const emoji = conclusion === 'failure' ? '❌' : conclusion === 'neutral' ? '⚠️' : '✅';
            let body;
            if (skipped) {
              body = [
                marker,
                `## ${emoji} Ctrlscan Self Scan`,
                '',
                'Status: skipped',
                '',
                `Reason: ${{ steps.parse.outputs.skip_reason }}`,
              ].join('\n');
            } else {
              const fs = require('fs');
              const runUrl = `${context.serverUrl}/${context.repo.owner}/${context.repo.repo}/actions/runs/${context.runId}`;
              const artifactId = '${{ steps.upload_artifacts.outputs.artifact-id }}';
              const artifactUrl = artifactId ? `${runUrl}/artifacts/${artifactId}` : '';
              let findingsPreview = '';
              try {
                if (fs.existsSync('reports/findings-top.md')) {
                  const raw = fs.readFileSync('reports/findings-top.md', 'utf8').trim();
                  // Keep PR comments compact
                  const lines = raw.split('\n').slice(0, 18);
                  findingsPreview = [
                    '',
                    '### Top Findings Preview',
                    '',
                    ...lines,
                    '',
                    artifactUrl
                      ? `_See [ctrlscan-self-scan-reports artifact](${artifactUrl}) for the full exported findings preview._`
                      : '_See `ctrlscan-self-scan-reports` artifact on the workflow run for the full exported findings preview._',
                  ].join('\n');
                }
              } catch (e) {
                findingsPreview = '';
              }
              body = [
                marker,
                `## ${emoji} Ctrlscan Self Scan`,
                '',
                `Repo: \`${{ steps.parse.outputs.repo || steps.target.outputs.scan_repo_url }}\`  `,
                `Branch: \`${{ steps.parse.outputs.branch || steps.target.outputs.scan_branch }}\`  `,
                `Scan Job: \`#${{ steps.parse.outputs.job_id }}\` (\`${{ steps.parse.outputs.job_status }}\`)  `,
                `Policy: \`${{ steps.parse.outputs.conclusion }}\` (fail on secrets or critical/high)`,
                `${{ steps.parse.outputs.ignored_high_findings != '0' && format('Policy exclusions: ignored {0} known false-positive high finding(s) for actions/download-artifact.', steps.parse.outputs.ignored_high_findings) || '' }}`,
                '',
                '### Scanner Counts',
                '',
                '| Scanner | Findings |',
                '|---|---:|',
                '| grype | ${{ steps.parse.outputs.grype_count }} |',
                '| opengrep | ${{ steps.parse.outputs.opengrep_count }} |',
                '| trufflehog | ${{ steps.parse.outputs.trufflehog_count }} |',
                '| trivy | ${{ steps.parse.outputs.trivy_count }} |',
                '| **Total** | **${{ steps.parse.outputs.total_findings }}** |',
                '',
                '### Severity Rollup',
                '',
                '| Critical | High | Medium | Low |',
                '|---:|---:|---:|---:|',
                '| ${{ steps.parse.outputs.critical }} | ${{ steps.parse.outputs.high }} | ${{ steps.parse.outputs.medium }} | ${{ steps.parse.outputs.low }} |',
                '',
                `Workflow run: ${runUrl}`,
                artifactUrl
                  ? `Artifacts: [ctrlscan-self-scan-reports](${artifactUrl})`
                  : 'Artifacts: see `ctrlscan-self-scan-reports` on the workflow run page.',
                findingsPreview,
              ].join('\n');
            }

            const { data: comments } = await github.rest.issues.listComments({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: context.issue.number,
              per_page: 100,
            });
            const existing = comments.find(c =>
              c.user?.type === 'Bot' && typeof c.body === 'string' && c.body.includes(marker)
            );
            if (existing) {
              await github.rest.issues.updateComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                comment_id: existing.id,
                body,
              });
            } else {
              await github.rest.issues.createComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                issue_number: context.issue.number,
                body,
              });
            }

      - name: Enforce self-scan policy
        if: ${{ always() && steps.parse.outputs.skipped != 'true' }}
        shell: bash
        run: |
          if [ "${{ steps.parse.outputs.conclusion }}" = "failure" ]; then
            echo "::error::Ctrlscan self-scan policy failed (secrets or critical/high findings detected, or scan command failed)."
            exit 1
          fi
