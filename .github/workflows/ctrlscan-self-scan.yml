name: Ctrlscan Self Scan

on:
  push:
    branches: [main]
  pull_request:
    branches: [main]
  workflow_dispatch:

permissions:
  contents: read

concurrency:
  group: ctrlscan-self-scan-${{ github.event.pull_request.number || github.ref }}
  cancel-in-progress: true

jobs:
  build:
    name: Build ctrlscan
    runs-on: ubuntu-latest
    steps:
      - name: Checkout
        uses: actions/checkout@34e114876b0b11c390a56381ad16ebd13914f8d5 # v4
        with:
          persist-credentials: false

      - name: Set up Go
        uses: actions/setup-go@40f1582b2485089dde7abd97c1529aa768e1baff # v5
        with:
          go-version: "1.25.7"
          cache: true

      - name: Build
        run: make build

      - name: Upload binary
        uses: actions/upload-artifact@ea165f8d65b6e75b540449e92b4886f43607fa02 # v4
        with:
          name: ctrlscan-linux-amd64
          path: ctrlscan
          retention-days: 1

  self-scan:
    name: Ctrlscan Self Scan
    runs-on: ubuntu-latest
    needs: build
    permissions:
      contents: read
      pull-requests: write
      issues: write
    steps:
      - name: Checkout
        uses: actions/checkout@34e114876b0b11c390a56381ad16ebd13914f8d5 # v4
        with:
          persist-credentials: false

      - name: Set up Go
        uses: actions/setup-go@40f1582b2485089dde7abd97c1529aa768e1baff # v5
        with:
          go-version: "1.25.7"
          cache: true

      - name: Download ctrlscan binary
        uses: actions/download-artifact@d3f86a106a0bac45b974a628896c90dbdf5c8093 # v4
        with:
          name: ctrlscan-linux-amd64

      - name: Make binary executable
        run: chmod +x ./ctrlscan

      - name: Prepare CI paths
        id: paths
        shell: bash
        run: |
          set -euo pipefail
          HOME_DIR="${RUNNER_TEMP}/ctrlscan-home"
          BIN_DIR="${HOME_DIR}/.ctrlscan/bin"
          DB_PATH="${RUNNER_TEMP}/ctrlscan-self-scan.db"
          CFG_PATH="${RUNNER_TEMP}/ctrlscan-ci-config.json"
          REPORT_DIR="${GITHUB_WORKSPACE}/reports"
          mkdir -p "${HOME_DIR}" "${BIN_DIR}" "${REPORT_DIR}"
          {
            echo "home_dir=${HOME_DIR}"
            echo "bin_dir=${BIN_DIR}"
            echo "db_path=${DB_PATH}"
            echo "cfg_path=${CFG_PATH}"
            echo "report_dir=${REPORT_DIR}"
          } >> "$GITHUB_OUTPUT"
          echo "${BIN_DIR}" >> "$GITHUB_PATH"

      - name: Install scanner tools
        shell: bash
        env:
          BIN_DIR: ${{ steps.paths.outputs.bin_dir }}
        run: |
          set -euo pipefail
          bash ./install/tools.sh --bin-dir "$BIN_DIR"
          echo "=== Tool Versions ==="
          syft version || true
          grype version || true
          opengrep --version || true
          trivy --version || true
          trufflehog --version || true

      - name: Create ctrlscan CI config
        shell: bash
        env:
          GH_REPO_TOKEN: ${{ github.token }}
          DB_PATH: ${{ steps.paths.outputs.db_path }}
          BIN_DIR: ${{ steps.paths.outputs.bin_dir }}
          CFG_PATH: ${{ steps.paths.outputs.cfg_path }}
        run: |
          set -euo pipefail
          python3 - <<'PY'
          import json, os
          cfg = {
              "database": {"driver": "sqlite", "path": os.environ["DB_PATH"], "dsn": ""},
              "ai": {"provider": "none", "openai_api_key": "", "model": "gpt-4o", "base_url": "", "ollama_url": "http://localhost:11434"},
              "git": {
                  "github": [{"token": os.environ.get("GH_REPO_TOKEN", ""), "host": "github.com"}],
                  "gitlab": [],
                  "azure": []
              },
              "agent": {
                  "mode": "triage",
                  "workers": 2,
                  "scan_targets": ["own_repos"],
                  "watchlist": [],
                  "scanners": ["grype", "opengrep", "trufflehog", "trivy"]
              },
              "tools": {"bin_dir": os.environ["BIN_DIR"], "prefer_docker": False},
              "gateway": {"port": 6080}
          }
          with open(os.environ["CFG_PATH"], "w", encoding="utf-8") as f:
              json.dump(cfg, f, indent=2)
          PY

      - name: Determine scan target
        id: target
        shell: bash
        env:
          EVENT_NAME: ${{ github.event_name }}
          PR_HEAD_FULL_NAME: ${{ github.event.pull_request.head.repo.full_name }}
          REPOSITORY: ${{ github.repository }}
          PR_HEAD_CLONE_URL: ${{ github.event.pull_request.head.repo.clone_url }}
          PR_HEAD_REF: ${{ github.event.pull_request.head.ref }}
          PR_HEAD_SHA: ${{ github.event.pull_request.head.sha }}
          REF_NAME: ${{ github.ref_name }}
          SHA: ${{ github.sha }}
        run: |
          set -euo pipefail
          if [ "$EVENT_NAME" = "pull_request" ]; then
            if [ "$PR_HEAD_FULL_NAME" != "$REPOSITORY" ]; then
              echo "skip_scan=true" >> "$GITHUB_OUTPUT"
              echo "skip_reason=Fork PRs are skipped by self-scan because ctrlscan scan clones by repo URL and cannot safely use elevated tokens on untrusted fork code." >> "$GITHUB_OUTPUT"
              exit 0
            fi
            {
              echo "scan_repo_url=$PR_HEAD_CLONE_URL"
              echo "scan_branch=$PR_HEAD_REF"
              echo "head_sha=$PR_HEAD_SHA"
            } >> "$GITHUB_OUTPUT"
          else
            {
              echo "scan_repo_url=https://github.com/$REPOSITORY"
              echo "scan_branch=$REF_NAME"
              echo "head_sha=$SHA"
            } >> "$GITHUB_OUTPUT"
          fi
          echo "skip_scan=false" >> "$GITHUB_OUTPUT"

      - name: Run ctrlscan self scan
        id: scan
        if: steps.target.outputs.skip_scan != 'true'
        shell: bash
        env:
          CTRLSCAN_HOME: ${{ steps.paths.outputs.home_dir }}
          CTRLSCAN_CFG: ${{ steps.paths.outputs.cfg_path }}
          SCAN_REPO_URL: ${{ steps.target.outputs.scan_repo_url }}
          SCAN_BRANCH: ${{ steps.target.outputs.scan_branch }}
          REPORT_DIR: ${{ steps.paths.outputs.report_dir }}
        run: |
          set +e
          mkdir -p "$REPORT_DIR"
          HOME="$CTRLSCAN_HOME" \
          ./ctrlscan --config "$CTRLSCAN_CFG" scan \
            --repo "$SCAN_REPO_URL" \
            --branch "$SCAN_BRANCH" \
            --scanners grype,opengrep,trufflehog,trivy \
            --parallel \
            2>&1 | tee "$REPORT_DIR/ctrlscan-scan.log"
          scan_exit=${PIPESTATUS[0]}
          echo "scan_exit=${scan_exit}" >> "$GITHUB_OUTPUT"
          exit 0

      - name: Parse scan results from SQLite
        id: parse
        if: always()
        shell: bash
        env:
          DB_PATH: ${{ steps.paths.outputs.db_path }}
          REPORT_DIR: ${{ steps.paths.outputs.report_dir }}
          SKIP_SCAN: ${{ steps.target.outputs.skip_scan }}
          SKIP_REASON: ${{ steps.target.outputs.skip_reason }}
          SCAN_EXIT: ${{ steps.scan.outputs.scan_exit }}
        run: |
          set -euo pipefail
          python3 - <<'PY'
          import json, os, sqlite3, sys
          out = os.environ["GITHUB_OUTPUT"]
          report_dir = os.environ["REPORT_DIR"]
          db_path = os.environ["DB_PATH"]
          skip_scan = os.environ.get("SKIP_SCAN", "false") == "true"
          scan_exit = int(os.environ.get("SCAN_EXIT", "0") or "0")

          summary = {
            "skipped": skip_scan,
            "skip_reason": os.environ.get("SKIP_REASON", ""),
            "scan_exit": scan_exit,
            "job_id": None,
            "job_status": "skipped" if skip_scan else "unknown",
            "repo": "",
            "branch": "",
            "critical": 0, "high": 0, "medium": 0, "low": 0,
            "policy_critical": 0, "policy_high": 0,
            "ignored_high_findings": 0,
            "scanner_counts": {"grype": 0, "opengrep": 0, "trufflehog": 0, "trivy": 0},
            "total_scanner_findings": 0,
            "conclusion": "success",
          }

          if skip_scan:
            summary["conclusion"] = "success"
          elif not os.path.exists(db_path):
            summary["conclusion"] = "failure" if scan_exit != 0 else "neutral"
            summary["job_status"] = "no_db"
          else:
            con = sqlite3.connect(db_path)
            con.row_factory = sqlite3.Row
            cur = con.cursor()
            cur.execute("""
              SELECT id, owner, repo, branch, status,
                     findings_critical, findings_high, findings_medium, findings_low
              FROM scan_jobs ORDER BY id DESC LIMIT 1
            """)
            row = cur.fetchone()
            if row:
              summary["job_id"] = row["id"]
              summary["job_status"] = row["status"]
              summary["repo"] = f'{row["owner"]}/{row["repo"]}'
              summary["branch"] = row["branch"]
              summary["critical"] = int(row["findings_critical"] or 0)
              summary["high"] = int(row["findings_high"] or 0)
              summary["medium"] = int(row["findings_medium"] or 0)
              summary["low"] = int(row["findings_low"] or 0)

              cur.execute("""
                SELECT scanner_name, COALESCE(SUM(findings_count), 0) AS n
                FROM scan_job_scanners WHERE scan_job_id = ?
                GROUP BY scanner_name
              """, (row["id"],))
              for r in cur.fetchall():
                summary["scanner_counts"][r["scanner_name"]] = int(r["n"] or 0)
              summary["total_scanner_findings"] = sum(summary["scanner_counts"].values())

              summary["policy_critical"] = summary["critical"]
              summary["policy_high"] = summary["high"]

              cur.execute("SELECT vulnerability_id, package_name, severity FROM sca_vulns WHERE scan_job_id = ?", (row["id"],))
              for vuln in cur.fetchall():
                vuln_id = (vuln["vulnerability_id"] or "").strip()
                pkg = (vuln["package_name"] or "").strip()
                sev = (vuln["severity"] or "").strip().lower()
                if vuln_id == "GHSA-cxww-7g56-2vh6" and pkg == "actions/download-artifact" and sev == "high":
                  summary["ignored_high_findings"] += 1
                  if summary["policy_high"] > 0:
                    summary["policy_high"] -= 1

            con.close()

            if scan_exit != 0:
              summary["conclusion"] = "failure"
            elif summary["scanner_counts"].get("trufflehog", 0) > 0:
              summary["conclusion"] = "failure"
            elif summary["policy_critical"] > 0 or summary["policy_high"] > 0:
              summary["conclusion"] = "failure"
            elif summary["medium"] > 0 or summary["scanner_counts"].get("trivy", 0) > 0:
              summary["conclusion"] = "neutral"
            else:
              summary["conclusion"] = "success"

          os.makedirs(report_dir, exist_ok=True)
          with open(os.path.join(report_dir, "self-scan-summary.json"), "w", encoding="utf-8") as f:
            json.dump(summary, f, indent=2)

          with open(out, "a", encoding="utf-8") as f:
            for key, value in [
              ("skipped", str(summary["skipped"]).lower()),
              ("skip_reason", summary["skip_reason"]),
              ("scan_exit", str(summary["scan_exit"])),
              ("job_id", "" if summary["job_id"] is None else str(summary["job_id"])),
              ("job_status", summary["job_status"]),
              ("repo", summary["repo"]), ("branch", summary["branch"]),
              ("critical", str(summary["critical"])), ("high", str(summary["high"])),
              ("medium", str(summary["medium"])), ("low", str(summary["low"])),
              ("policy_critical", str(summary["policy_critical"])),
              ("policy_high", str(summary["policy_high"])),
              ("ignored_high_findings", str(summary["ignored_high_findings"])),
              ("grype_count", str(summary["scanner_counts"].get("grype", 0))),
              ("opengrep_count", str(summary["scanner_counts"].get("opengrep", 0))),
              ("trufflehog_count", str(summary["scanner_counts"].get("trufflehog", 0))),
              ("trivy_count", str(summary["scanner_counts"].get("trivy", 0))),
              ("total_findings", str(summary["total_scanner_findings"])),
              ("conclusion", summary["conclusion"]),
            ]:
              f.write(f"{key}={value}\n")
          PY

      - name: Export finding details from SQLite
        id: details
        if: ${{ always() && steps.parse.outputs.skipped != 'true' && steps.parse.outputs.job_id != '' }}
        shell: bash
        env:
          DB_PATH: ${{ steps.paths.outputs.db_path }}
          REPORT_DIR: ${{ steps.paths.outputs.report_dir }}
          JOB_ID: ${{ steps.parse.outputs.job_id }}
        run: |
          set -euo pipefail
          python3 - <<'PY'
          import json, os, sqlite3

          db_path = os.environ["DB_PATH"]
          report_dir = os.environ["REPORT_DIR"]
          job_id = int(os.environ["JOB_ID"])
          out = os.environ["GITHUB_OUTPUT"]

          os.makedirs(report_dir, exist_ok=True)
          con = sqlite3.connect(db_path)
          con.row_factory = sqlite3.Row
          cur = con.cursor()

          severity_rank = {
              "CRITICAL": 5, "Critical": 5, "critical": 5,
              "HIGH": 4, "High": 4, "high": 4, "ERROR": 4, "Error": 4, "error": 4,
              "MEDIUM": 3, "Medium": 3, "medium": 3, "WARNING": 3, "Warning": 3, "warning": 3,
              "LOW": 2, "Low": 2, "low": 2,
              "INFO": 1, "Info": 1, "info": 1,
          }

          findings = []

          def add(table, kind, cols_sql, mapper):
              q = f"SELECT {cols_sql} FROM {table} WHERE scan_job_id = ?"
              try:
                  cur.execute(q, (job_id,))
                  for row in cur.fetchall():
                      findings.append(mapper(row))
              except sqlite3.OperationalError:
                  return

          add("sast_findings", "sast",
              "id, severity, check_id, file_path, line_start, message, status",
              lambda r: {"kind": "sast", "severity": r["severity"] or "", "rule": r["check_id"] or "",
                  "location": f'{r["file_path"]}:{r["line_start"]}' if (r["file_path"] or "") else "",
                  "title": (r["message"] or "")[:200], "status": r["status"] or ""})
          add("sca_vulns", "sca",
              "id, severity, vulnerability_id, package_name, version_affected, version_remediation, status",
              lambda r: {"kind": "sca", "severity": r["severity"] or "", "rule": r["vulnerability_id"] or "",
                  "location": (r["package_name"] or "") + (f'@{r["version_affected"]}' if (r["version_affected"] or "") else ""),
                  "title": ("fix " + (r["version_remediation"] or "")) if (r["version_remediation"] or "") else "",
                  "status": r["status"] or ""})
          add("secrets_findings", "secrets",
              "id, severity, detector_name, detector_type, file_path, line_number, status",
              lambda r: {"kind": "secrets", "severity": r["severity"] or "",
                  "rule": (r["detector_name"] or "") + (f'/{r["detector_type"]}' if (r["detector_type"] or "") else ""),
                  "location": f'{r["file_path"]}:{r["line_number"]}' if (r["file_path"] or "") else "",
                  "title": "Potential secret detected", "status": r["status"] or ""})
          add("iac_findings", "iac",
              "id, severity, check_id, title, file_path, line_start, status",
              lambda r: {"kind": "iac", "severity": r["severity"] or "", "rule": r["check_id"] or "",
                  "location": f'{r["file_path"]}:{r["line_start"]}' if (r["file_path"] or "") else "",
                  "title": (r["title"] or "")[:200], "status": r["status"] or ""})

          details_source = "sqlite"

          def to_text(b):
              if b is None:
                  return ""
              if isinstance(b, (bytes, bytearray)):
                  return b.decode("utf-8", errors="replace")
              return str(b)

          def append_finding(kind, severity, rule, location, title, status="open"):
              findings.append({
                  "kind": kind or "",
                  "severity": severity or "",
                  "rule": rule or "",
                  "location": location or "",
                  "title": (title or "")[:200],
                  "status": status or "",
              })

          def parse_opengrep_raw(raw_text):
              try:
                  payload = json.loads(raw_text or "{}")
              except Exception:
                  return
              for r in payload.get("results", []) or []:
                  extra = r.get("extra") or {}
                  start = r.get("start") or {}
                  loc = r.get("path") or ""
                  line = start.get("line")
                  if loc and line:
                      loc = f"{loc}:{line}"
                  append_finding(
                      "sast",
                      extra.get("severity", ""),
                      r.get("check_id", ""),
                      loc,
                      extra.get("message", ""),
                      "open",
                  )

          def parse_trivy_raw(raw_text):
              try:
                  payload = json.loads(raw_text or "{}")
              except Exception:
                  return
              for res in payload.get("Results", []) or []:
                  target = res.get("Target") or ""
                  for m in res.get("Misconfigurations", []) or []:
                      line = (((m.get("IacMetadata") or {}).get("StartLine")) or 0)
                      loc = f"{target}:{line}" if (target and line) else target
                      title = m.get("Title") or m.get("Description") or ""
                      append_finding(
                          "iac",
                          m.get("Severity", ""),
                          m.get("ID", ""),
                          loc,
                          title,
                          m.get("Status", "") or "open",
                      )

          def parse_grype_raw(raw_text):
              try:
                  payload = json.loads(raw_text or "{}")
              except Exception:
                  return
              for m in payload.get("matches", []) or []:
                  vuln = m.get("vulnerability") or {}
                  art = m.get("artifact") or {}
                  locations = art.get("locations") or []
                  loc = ""
                  if locations:
                      first = locations[0] or {}
                      loc = first.get("path") or first.get("realPath") or ""
                  if not loc:
                      name = art.get("name") or ""
                      ver = art.get("version") or ""
                      loc = f"{name}@{ver}" if (name and ver) else (name or "")
                  fix_versions = vuln.get("fix", {}).get("versions") or []
                  title = ""
                  if fix_versions:
                      title = f'fix {", ".join(str(v) for v in fix_versions[:3])}'
                  append_finding(
                      "sca",
                      vuln.get("severity", ""),
                      vuln.get("id", ""),
                      loc,
                      title,
                      "open",
                  )

          def _deep_find_file_and_line(obj):
              file_path = ""
              line_no = 0
              if isinstance(obj, dict):
                  for k, v in obj.items():
                      lk = str(k).lower()
                      if not file_path and lk in ("file", "filepath", "path") and isinstance(v, str):
                          file_path = v
                      if not line_no and lk in ("line", "linenumber") and isinstance(v, int):
                          line_no = v
                  for v in obj.values():
                      if file_path and line_no:
                          break
                      f, l = _deep_find_file_and_line(v)
                      file_path = file_path or f
                      line_no = line_no or l
              elif isinstance(obj, list):
                  for item in obj:
                      f, l = _deep_find_file_and_line(item)
                      if f or l:
                          return f, l
              return file_path, line_no

          def parse_trufflehog_raw(raw_text):
              for line in (raw_text or "").splitlines():
                  line = line.strip()
                  if not line:
                      continue
                  try:
                      obj = json.loads(line)
                  except Exception:
                      continue
                  verified = bool(obj.get("Verified"))
                  sev = "HIGH" if verified else "MEDIUM"
                  detector_name = obj.get("DetectorName") or ""
                  detector_type = obj.get("DetectorType") or ""
                  rule = detector_name + (f"/{detector_type}" if detector_type else "")
                  file_path, line_no = _deep_find_file_and_line(obj.get("SourceMetadata") or {})
                  loc = f"{file_path}:{line_no}" if (file_path and line_no) else (file_path or "")
                  append_finding(
                      "secrets",
                      sev,
                      rule,
                      loc,
                      "Potential secret detected",
                      "open",
                  )

          # Fallback: parse raw scanner outputs if normalized finding tables are empty.
          if not findings:
              try:
                  cur.execute(
                      "SELECT scanner_name, content_type, raw_output FROM scan_job_raw_outputs WHERE scan_job_id = ?",
                      (job_id,),
                  )
                  raw_rows = cur.fetchall()
              except sqlite3.OperationalError:
                  raw_rows = []
              if raw_rows:
                  details_source = "raw"
              for rr in raw_rows:
                  scanner = (rr["scanner_name"] or "").strip().lower()
                  raw_text = to_text(rr["raw_output"])
                  if not raw_text.strip():
                      continue
                  if scanner == "opengrep":
                      parse_opengrep_raw(raw_text)
                  elif scanner == "trivy":
                      parse_trivy_raw(raw_text)
                  elif scanner == "grype":
                      parse_grype_raw(raw_text)
                  elif scanner == "trufflehog":
                      parse_trufflehog_raw(raw_text)

          findings.sort(key=lambda f: (-severity_rank.get(f["severity"], 0), f["kind"], f["location"], f["rule"]))
          top = findings[:20]

          with open(os.path.join(report_dir, "findings-top.json"), "w", encoding="utf-8") as f:
              json.dump(top, f, indent=2)

          md_lines = [f"# Top Findings ({'from SQLite' if details_source == 'sqlite' else 'from raw scanner outputs fallback'})", "", f"Scan Job: #{job_id}", ""]
          if not top:
              md_lines.append("No normalized findings rows found for this scan job.")
          else:
              md_lines.extend(["| Kind | Severity | Rule/CVE | Location | Detail | Status |", "|---|---|---|---|---|---|"])
              for item in top:
                  def esc(s):
                      return str(s or "").replace("|", "\\|").replace("\n", " ").strip()
                  md_lines.append(
                      f'| {esc(item["kind"])} | {esc(item["severity"])} | {esc(item["rule"])} | {esc(item["location"])} | {esc(item["title"])} | {esc(item["status"])} |')

          preview_md = "\n".join(md_lines) + "\n"
          preview_path = os.path.join(report_dir, "findings-top.md")
          with open(preview_path, "w", encoding="utf-8") as f:
              f.write(preview_md)

          with open(out, "a", encoding="utf-8") as f:
              f.write(f"has_details={'true' if bool(top) else 'false'}\n")
              f.write(f"details_source={details_source}\n")
              f.write(f"details_markdown_path={preview_path}\n")
          con.close()
          PY

      - name: Publish job summary
        if: always()
        shell: bash
        env:
          PARSE_SKIPPED: ${{ steps.parse.outputs.skipped }}
          PARSE_SKIP_REASON: ${{ steps.parse.outputs.skip_reason }}
          PARSE_REPO: ${{ steps.parse.outputs.repo }}
          TARGET_REPO_URL: ${{ steps.target.outputs.scan_repo_url }}
          PARSE_BRANCH: ${{ steps.parse.outputs.branch }}
          TARGET_BRANCH: ${{ steps.target.outputs.scan_branch }}
          PARSE_SCAN_EXIT: ${{ steps.parse.outputs.scan_exit }}
          PARSE_JOB_ID: ${{ steps.parse.outputs.job_id }}
          PARSE_JOB_STATUS: ${{ steps.parse.outputs.job_status }}
          PARSE_GRYPE: ${{ steps.parse.outputs.grype_count }}
          PARSE_OPENGREP: ${{ steps.parse.outputs.opengrep_count }}
          PARSE_TRUFFLEHOG: ${{ steps.parse.outputs.trufflehog_count }}
          PARSE_TRIVY: ${{ steps.parse.outputs.trivy_count }}
          PARSE_TOTAL: ${{ steps.parse.outputs.total_findings }}
          PARSE_CRITICAL: ${{ steps.parse.outputs.critical }}
          PARSE_HIGH: ${{ steps.parse.outputs.high }}
          PARSE_MEDIUM: ${{ steps.parse.outputs.medium }}
          PARSE_LOW: ${{ steps.parse.outputs.low }}
          PARSE_IGNORED_HIGH: ${{ steps.parse.outputs.ignored_high_findings }}
          PARSE_CONCLUSION: ${{ steps.parse.outputs.conclusion }}
        run: |
          {
            echo "## Ctrlscan Self Scan"
            echo ""
            if [ "$PARSE_SKIPPED" = "true" ]; then
              echo "- Status: skipped"
              echo "- Reason: $PARSE_SKIP_REASON"
              exit 0
            fi
            echo "- Repo: \`${PARSE_REPO:-$TARGET_REPO_URL}\`"
            echo "- Branch: \`${PARSE_BRANCH:-$TARGET_BRANCH}\`"
            echo "- Scan command exit: \`$PARSE_SCAN_EXIT\`"
            echo "- Scan job: \`#$PARSE_JOB_ID\` (\`$PARSE_JOB_STATUS\`)"
            echo ""
            echo "### Scanner Counts"
            echo ""
            echo "| Scanner | Findings |"
            echo "|---|---:|"
            echo "| grype | $PARSE_GRYPE |"
            echo "| opengrep | $PARSE_OPENGREP |"
            echo "| trufflehog | $PARSE_TRUFFLEHOG |"
            echo "| trivy | $PARSE_TRIVY |"
            echo "| **Total** | **$PARSE_TOTAL** |"
            echo ""
            echo "### Severity Rollup"
            echo ""
            echo "| Critical | High | Medium | Low |"
            echo "|---:|---:|---:|---:|"
            echo "| $PARSE_CRITICAL | $PARSE_HIGH | $PARSE_MEDIUM | $PARSE_LOW |"
            echo ""
            if [ "$PARSE_IGNORED_HIGH" != "0" ]; then
              echo "- Policy exclusions applied: ignored \`$PARSE_IGNORED_HIGH\` known false-positive high finding(s) for \`actions/download-artifact\` GHSA version normalization."
              echo ""
            fi
            echo "Policy result: \`$PARSE_CONCLUSION\` (fail on secrets or critical/high)"
            if [ -f "reports/findings-top.md" ]; then
              echo ""
              cat "reports/findings-top.md"
            fi
          } >> "$GITHUB_STEP_SUMMARY"

      - name: Upload scan artifacts
        id: upload_artifacts
        if: always()
        uses: actions/upload-artifact@ea165f8d65b6e75b540449e92b4886f43607fa02 # v4
        with:
          name: ctrlscan-self-scan-reports
          path: |
            reports/
          retention-days: 14

      - name: Append artifact links to summary
        if: always()
        shell: bash
        env:
          SERVER_URL: ${{ github.server_url }}
          REPO: ${{ github.repository }}
          RUN_ID: ${{ github.run_id }}
          ARTIFACT_ID: ${{ steps.upload_artifacts.outputs.artifact-id }}
        run: |
          run_url="${SERVER_URL}/${REPO}/actions/runs/${RUN_ID}"
          {
            echo ""
            echo "### Links"
            echo ""
            echo "- Workflow run: ${run_url}"
            if [ -n "${ARTIFACT_ID}" ]; then
              echo "- Artifact: ${run_url}/artifacts/${ARTIFACT_ID}"
            else
              echo "- Artifact: ctrlscan-self-scan-reports (see workflow run page)"
            fi
          } >> "$GITHUB_STEP_SUMMARY"

      - name: Comment on PR with self-scan summary
        if: ${{ always() && github.event_name == 'pull_request' }}
        continue-on-error: true
        uses: actions/github-script@f28e40c7f34bde8b3046d885e986cb6290c5673b # v7
        env:
          PARSE_SKIPPED: ${{ steps.parse.outputs.skipped }}
          PARSE_CONCLUSION: ${{ steps.parse.outputs.conclusion }}
          PARSE_SKIP_REASON: ${{ steps.parse.outputs.skip_reason }}
          PARSE_REPO: ${{ steps.parse.outputs.repo }}
          TARGET_REPO_URL: ${{ steps.target.outputs.scan_repo_url }}
          PARSE_BRANCH: ${{ steps.parse.outputs.branch }}
          TARGET_BRANCH: ${{ steps.target.outputs.scan_branch }}
          PARSE_JOB_ID: ${{ steps.parse.outputs.job_id }}
          PARSE_JOB_STATUS: ${{ steps.parse.outputs.job_status }}
          PARSE_IGNORED_HIGH: ${{ steps.parse.outputs.ignored_high_findings }}
          PARSE_GRYPE: ${{ steps.parse.outputs.grype_count }}
          PARSE_OPENGREP: ${{ steps.parse.outputs.opengrep_count }}
          PARSE_TRUFFLEHOG: ${{ steps.parse.outputs.trufflehog_count }}
          PARSE_TRIVY: ${{ steps.parse.outputs.trivy_count }}
          PARSE_TOTAL: ${{ steps.parse.outputs.total_findings }}
          PARSE_CRITICAL: ${{ steps.parse.outputs.critical }}
          PARSE_HIGH: ${{ steps.parse.outputs.high }}
          PARSE_MEDIUM: ${{ steps.parse.outputs.medium }}
          PARSE_LOW: ${{ steps.parse.outputs.low }}
          ARTIFACT_ID: ${{ steps.upload_artifacts.outputs.artifact-id }}
        with:
          script: |
            const marker = '<!-- ctrlscan-self-scan -->';
            const skipped = process.env.PARSE_SKIPPED === 'true';
            const conclusion = process.env.PARSE_CONCLUSION || 'unknown';
            const emoji = conclusion === 'failure' ? '❌' : conclusion === 'neutral' ? '⚠️' : '✅';
            let body;
            if (skipped) {
              body = [
                marker,
                `## ${emoji} Ctrlscan Self Scan`,
                '',
                'Status: skipped',
                '',
                `Reason: ${process.env.PARSE_SKIP_REASON}`,
              ].join('\n');
            } else {
              const fs = require('fs');
              const runUrl = `${context.serverUrl}/${context.repo.owner}/${context.repo.repo}/actions/runs/${context.runId}`;
              const artifactId = process.env.ARTIFACT_ID || '';
              const artifactUrl = artifactId ? `${runUrl}/artifacts/${artifactId}` : '';
              let findingsPreview = '';
              try {
                if (fs.existsSync('reports/findings-top.md')) {
                  const raw = fs.readFileSync('reports/findings-top.md', 'utf8').trim();
                  const lines = raw.split('\n').slice(0, 18);
                  findingsPreview = [
                    '',
                    '### Top Findings Preview',
                    '',
                    ...lines,
                    '',
                    artifactUrl
                      ? `_See [ctrlscan-self-scan-reports artifact](${artifactUrl}) for the full exported findings preview._`
                      : '_See `ctrlscan-self-scan-reports` artifact on the workflow run for the full exported findings preview._',
                  ].join('\n');
                }
              } catch (e) {
                findingsPreview = '';
              }
              const ignoredHigh = parseInt(process.env.PARSE_IGNORED_HIGH || '0', 10);
              const policyExclusion = ignoredHigh > 0
                ? `Policy exclusions: ignored ${ignoredHigh} known false-positive high finding(s) for actions/download-artifact.`
                : '';
              body = [
                marker,
                `## ${emoji} Ctrlscan Self Scan`,
                '',
                `Repo: \`${process.env.PARSE_REPO || process.env.TARGET_REPO_URL}\`  `,
                `Branch: \`${process.env.PARSE_BRANCH || process.env.TARGET_BRANCH}\`  `,
                `Scan Job: \`#${process.env.PARSE_JOB_ID}\` (\`${process.env.PARSE_JOB_STATUS}\`)  `,
                `Policy: \`${conclusion}\` (fail on secrets or critical/high)`,
                policyExclusion,
                '',
                '### Scanner Counts',
                '',
                '| Scanner | Findings |',
                '|---|---:|',
                `| grype | ${process.env.PARSE_GRYPE} |`,
                `| opengrep | ${process.env.PARSE_OPENGREP} |`,
                `| trufflehog | ${process.env.PARSE_TRUFFLEHOG} |`,
                `| trivy | ${process.env.PARSE_TRIVY} |`,
                `| **Total** | **${process.env.PARSE_TOTAL}** |`,
                '',
                '### Severity Rollup',
                '',
                '| Critical | High | Medium | Low |',
                '|---:|---:|---:|---:|',
                `| ${process.env.PARSE_CRITICAL} | ${process.env.PARSE_HIGH} | ${process.env.PARSE_MEDIUM} | ${process.env.PARSE_LOW} |`,
                '',
                `Workflow run: ${runUrl}`,
                artifactUrl
                  ? `Artifacts: [ctrlscan-self-scan-reports](${artifactUrl})`
                  : 'Artifacts: see `ctrlscan-self-scan-reports` on the workflow run page.',
                findingsPreview,
              ].join('\n');
            }

            const { data: comments } = await github.rest.issues.listComments({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: context.issue.number,
              per_page: 100,
            });
            const existing = comments.find(c =>
              c.user?.type === 'Bot' && typeof c.body === 'string' && c.body.includes(marker)
            );
            if (existing) {
              await github.rest.issues.updateComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                comment_id: existing.id,
                body,
              });
            } else {
              await github.rest.issues.createComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                issue_number: context.issue.number,
                body,
              });
            }

      - name: Enforce self-scan policy
        if: ${{ always() && steps.parse.outputs.skipped != 'true' }}
        shell: bash
        env:
          CONCLUSION: ${{ steps.parse.outputs.conclusion }}
        run: |
          if [ "$CONCLUSION" = "failure" ]; then
            echo "::error::Ctrlscan self-scan policy failed (secrets or critical/high findings detected, or scan command failed)."
            exit 1
          fi
